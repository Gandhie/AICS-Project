{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ln: failed to create symbolic link 'data/data': File exists\r\n"
     ]
    }
   ],
   "source": [
    "! ln -s /usr/local/courses/lt2318/data/ data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image_data.json      objects.pickle\t       relationships.json.zip\r\n",
      "image_data.json.zip  read_objects_resnet50.py  VG_100K\r\n",
      "images2.zip\t     region_descriptions.json  VG_100K_2\r\n",
      "images.zip\t     relationships.json\r\n"
     ]
    }
   ],
   "source": [
    "! ls data/visual_genome/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from collections import Counter, defaultdict\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read from file\n",
    "relationships_from_file = json.load(open('data/visual_genome/relationships.json'))\n",
    "\n",
    "# name/names correction for reading content of nodes in the dataset\n",
    "name_extract = lambda x: x['names'][0].lower() if 'names' in x and len(x['names']) else x['name'].lower() if 'name' in x else '' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of images: 108077\n"
     ]
    }
   ],
   "source": [
    "print('number of images:', len(relationships_from_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_data_from_file = json.load(open('data/visual_genome/image_data.json'))\n",
    "image_id_to_size = {\n",
    "    image_data['image_id']: (image_data['width'], image_data['height'])\n",
    "    for image_data in image_data_from_file\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions for getting descriptions (relations) and bounding boxes (which are normalised by image size in the process).\n",
    "def get_description(relations_data):\n",
    "    triplet = (\n",
    "        name_extract(relation_data['subject']),\n",
    "        relation_data['predicate'].lower(), # synset?\n",
    "        name_extract(relation_data['object']),\n",
    "    )\n",
    "    \n",
    "    return triplet\n",
    "\n",
    "def get_bboxes(relations_data, size):\n",
    "    w0, h0 = size\n",
    "    def normalize(bbox):\n",
    "        x, y, w, h = bbox\n",
    "        return (x/w0, y/h0, w/w0, h/h0, )\n",
    "    \n",
    "    bboxes = (\n",
    "        normalize([relation_data['subject'][d] for d in ['x', 'y', 'w', 'h', ]]),\n",
    "        normalize([relation_data['object'][d] for d in ['x', 'y', 'w', 'h', ]]),\n",
    "    )\n",
    "    \n",
    "    return bboxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepositions = ['over', 'above', 'below', 'under', 'on', 'in', 'right of', 'left of', 'at', 'by', 'nearby', 'with', 'within', 'near', 'underneath', 'on top of', 'against', 'around', 'behind', 'in front of', 'amid', 'amidst', 'between', 'beneath', 'between', 'beside', 'inside', 'alongside', 'upon', ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading visual data.\n",
    "with open('/usr/local/courses/lt2318/data/visual_genome/objects.pickle', 'rb') as f:\n",
    "    visual_features = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for getting the visual feature vectors from the previous loaded file based on the object_id of the subject and object in a relation.\n",
    "def get_vis_vecs(relations_data, vis_features):\n",
    "    subid = relations_data['subject']['object_id']\n",
    "    objid = relations_data['object']['object_id']\n",
    "    \n",
    "    try:\n",
    "        target_vf = vis_features[subid]\n",
    "    except KeyError:\n",
    "        target_vf = None\n",
    "    try:\n",
    "        landmark_vf = vis_features[objid]\n",
    "    except KeyError:\n",
    "        landmark_vf = None\n",
    "                \n",
    "    return target_vf, landmark_vf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a dictionary which contains another dictionary for each preposition, which contains two lists - one for targets and one for landmarks.\n",
    "prep_vis_feat = {\n",
    "    p: {}\n",
    "    for p in prepositions\n",
    "}\n",
    "\n",
    "for p in prep_vis_feat:\n",
    "    prep_vis_feat[p]['target'] = []\n",
    "    prep_vis_feat[p]['landmark'] = []\n",
    "\n",
    "# Gets visual feature vectors for relations if their predicate is one of the prepositions in question.\n",
    "# Also checks that there are both target and landmark for each relation, and only keeps the ones that have the full pairs.\n",
    "# This was to deal with the fact that I was initially getting different numbers of targets and landmarks.\n",
    "for img_relations in relationships_from_file:\n",
    "    for relation_data in img_relations['relationships']:\n",
    "        _, p, _ = get_description(relation_data)\n",
    "        \n",
    "        if p in prep_vis_feat:\n",
    "            target_vf, landmark_vf = get_vis_vecs(relation_data, visual_features)\n",
    "            \n",
    "            if target_vf is not None and landmark_vf is not None:\n",
    "                prep_vis_feat[p]['target'].append(target_vf)\n",
    "                prep_vis_feat[p]['landmark'].append(landmark_vf)\n",
    "            else:\n",
    "                pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over 8200 8200\n",
      "above 12583 12583\n",
      "below 3155 3155\n",
      "under 16985 16985\n",
      "on 544509 544509\n",
      "in 183951 183951\n",
      "right of 220 220\n",
      "left of 365 365\n",
      "at 8248 8248\n",
      "by 14801 14801\n",
      "nearby 0 0\n",
      "with 55352 55352\n",
      "within 107 107\n",
      "near 24637 24637\n",
      "underneath 1347 1347\n",
      "on top of 27906 27906\n",
      "against 2751 2751\n",
      "around 6846 6846\n",
      "behind 36336 36336\n",
      "in front of 11849 11849\n",
      "amid 33 33\n",
      "amidst 19 19\n",
      "between 2875 2875\n",
      "beneath 1266 1266\n",
      "beside 6914 6914\n",
      "inside 5672 5672\n",
      "alongside 386 386\n",
      "upon 15 15\n"
     ]
    }
   ],
   "source": [
    "for p in prep_vis_feat:\n",
    "    print(p, len(prep_vis_feat[p][\"target\"]), len(prep_vis_feat[p][\"landmark\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saves the dictionary containing all of the visual feature vectors divided by targets and landmark by preposition to file.\n",
    "with open('pvis_vecs.pkl', 'wb') as sf:\n",
    "    pickle.dump(prep_vis_feat, sf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2048,)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(prep_vis_feat[p][\"target\"])\n",
    "prep_vis_feat[p][\"target\"][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over \n",
      " Target variance: 0.4377860509985831 Landmark variance: 0.43583857570843\n",
      "above \n",
      " Target variance: 0.4416074931721027 Landmark variance: 0.4337125514527151\n",
      "below \n",
      " Target variance: 0.4496400695075702 Landmark variance: 0.45063913436680325\n",
      "under \n",
      " Target variance: 0.44614292008054934 Landmark variance: 0.44368264179195344\n",
      "on \n",
      " Target variance: 0.44018997637074353 Landmark variance: 0.4381616170161583\n",
      "in \n",
      " Target variance: 0.4511215118310238 Landmark variance: 0.44347445626513315\n",
      "right of \n",
      " Target variance: 0.4397678258744153 Landmark variance: 0.4418984124606306\n",
      "left of \n",
      " Target variance: 0.4399039305664681 Landmark variance: 0.4394029849669436\n",
      "at \n",
      " Target variance: 0.4149755984219559 Landmark variance: 0.40214101678784847\n",
      "by \n",
      " Target variance: 0.4326867802861043 Landmark variance: 0.42981732624659275\n",
      "nearby \n",
      " Target variance: nan Landmark variance: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.6/site-packages/ipykernel_launcher.py:18: RuntimeWarning: Mean of empty slice.\n",
      "/usr/lib64/python3.6/site-packages/numpy/core/_methods.py:80: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/usr/lib/python3.6/site-packages/ipykernel_launcher.py:19: RuntimeWarning: Mean of empty slice.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "with \n",
      " Target variance: 0.4315445705944343 Landmark variance: 0.43508339927591966\n",
      "within \n",
      " Target variance: 0.45050542237602664 Landmark variance: 0.43340833666168643\n",
      "near \n",
      " Target variance: 0.43485046399439503 Landmark variance: 0.43220760487269505\n",
      "underneath \n",
      " Target variance: 0.4429341913066091 Landmark variance: 0.44331571003996006\n",
      "on top of \n",
      " Target variance: 0.4362727468801956 Landmark variance: 0.42958939257289125\n",
      "against \n",
      " Target variance: 0.43067744498857796 Landmark variance: 0.4141680103449421\n",
      "around \n",
      " Target variance: 0.4437486544303681 Landmark variance: 0.4433920195654335\n",
      "behind \n",
      " Target variance: 0.43375089205801487 Landmark variance: 0.42392210322233326\n",
      "in front of \n",
      " Target variance: 0.428566336933596 Landmark variance: 0.41663956024297855\n",
      "amid \n",
      " Target variance: 0.4064665337403615 Landmark variance: 0.3808368697310939\n",
      "amidst \n",
      " Target variance: 0.422967614311921 Landmark variance: 0.4420478045940399\n",
      "between \n",
      " Target variance: 0.4483775362657464 Landmark variance: 0.4435649727686592\n",
      "beneath \n",
      " Target variance: 0.4526470781172998 Landmark variance: 0.45400014748034695\n",
      "beside \n",
      " Target variance: 0.4306099067792611 Landmark variance: 0.4232744517002555\n",
      "inside \n",
      " Target variance: 0.4388236723188705 Landmark variance: 0.42509424250851396\n",
      "alongside \n",
      " Target variance: 0.4078553673362485 Landmark variance: 0.37267645822905504\n",
      "upon \n",
      " Target variance: 0.36990825335184735 Landmark variance: 0.3693876008192698\n"
     ]
    }
   ],
   "source": [
    "# Takes all target and landmark vectors from prep_vis_feat. Sets a variable to the first vector of each set\n",
    "# and then adds them together (one addition version and one append version currently). \n",
    "from scipy.spatial.distance import cosine\n",
    "\n",
    "for p in prep_vis_feat:\n",
    "    targ_vecs = prep_vis_feat[p]['target']\n",
    "    landm_vecs = prep_vis_feat[p]['landmark']\n",
    "    \n",
    "    # creating centroids\n",
    "    targ_centroid = np.array(targ_vecs).sum(0)\n",
    "    landm_centroid = np.array(landm_vecs).sum(0)\n",
    "    \n",
    "    # cosine distances:\n",
    "    targ_cos = np.array([cosine(u, targ_centroid) for u in targ_vecs if np.linalg.norm(u) != 0])\n",
    "    landm_cos = np.array([cosine(u, landm_centroid) for u in landm_vecs if np.linalg.norm(u) != 0])\n",
    "    \n",
    "    # average cosine distances (variance):\n",
    "    targ_var = targ_cos.mean()\n",
    "    landm_var = landm_cos.mean()\n",
    "    \n",
    "    # print or save these numbers\n",
    "    print(p, \"\\n\", \"Target variance:\",  targ_var, \"Landmark variance:\", landm_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
